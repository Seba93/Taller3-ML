{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Reconocimiento de Imágenes en CIFAR10 <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.0 Importaciones necesarias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan módulos y funciones necesarias para trabajar en este problema. Para el trabajo con redes neuronales, se usará TensorFlow como backend de la librería Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import imread\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "from top_level_features import hog_features\n",
    "from top_level_features import color_histogram_hsv\n",
    "from top_level_features import extract_features\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor as Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Extracción de archivos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se extraen los bloques correspondientes al conjunto de entrenamiento y al conjunto de pruebas, por medio de la función *unpickle*, que retorna los datos en formato de diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Función para extracción de bloques de datos\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se extraen bloques de datos a utilizar\n",
    "db1 = unpickle('data_batch_1')\n",
    "db2 = unpickle('data_batch_2')\n",
    "db3 = unpickle('data_batch_3')\n",
    "db4 = unpickle('data_batch_4')\n",
    "db5 = unpickle('data_batch_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Construcción de matrices de entrenamiento, prueba y validación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por medio de la función *load_CIFAR_One*, es posible separar, para un determinado bloque, los atributos predictores y el atributo a predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separación de atributos predictores y atributo a predecir\n",
    "def load_CIFAR_one(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        return X, np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la función anterior, se procede a construir matricialmente los conjuntos de entrenamiento, prueba y validación con que se trabajará más adelante. Para ello, se implementa, la función *load_CIFAR10*. Notar que el conjunto de validación se crea permutando aleatoriamente las filas del conjunto de entrenamiento y posteriormente se seleccionan mil de estas filas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Se crean, matricialmente, conjuntos de entrenamiento, prueba y validación\n",
    "def load_CIFAR10(PATH):\n",
    "    #Creación de matrices de entrenamiento\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1, 6):\n",
    "        f = os.path.join(PATH, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_one(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    #Creación de matrices de prueba\n",
    "    Xts, Yts = load_CIFAR_one(os.path.join(PATH, 'test_batch'))\n",
    "    #Creación de matrices de validación\n",
    "    training_data = Xtr\n",
    "    training_data_y = Ytr.reshape((50000, 1))\n",
    "    training_data = np.append(training_data, training_data_y, axis=1)\n",
    "    np.random.shuffle(training_data)\n",
    "    Xv = training_data[:1000, :3072]\n",
    "    Yv = training_data[:1000, 3072]\n",
    "    return Xtr, Ytr, Xts, Yts, Xv, Yv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera, se crean las matrices Xtr e Ytr, que corresponden a las imágenes y labels de entrenamiento, Xts e Yts, similes de los anteriores para el caso de pruebas y Xv e Yv, similes de los anteriores para el caso de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr, Ytr, Xts, Yts, Xv, Yv = load_CIFAR10('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Normalización de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estudian dos estrategias de normalización: Primero, se experimenta dividiendo los datos de las matrices por la intensidad máxima de pixel de cada una. Se comprueba que para todas estas matrices, dicha intensidad es 255. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 255 255\n"
     ]
    }
   ],
   "source": [
    "print np.amax(Xtr), np.amax(Xts), np.amax(Xv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, se procede a dividir cada celda de las matrices Xtr, Xts y Xv por 255. Como consecuencia de esta operación, cada una de esta celdas posee un valor entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr_px = Xtr / float(np.amax(Xtr)) \n",
    "Xts_px = Xts / float(np.amax(Xts))\n",
    "Xv_px = Xv / float(np.amax(Xv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La segunda estrategia de normalización consiste en escalar los datos de tal forma de que estos sigan una distribución gaussiana de media 0 y varianza 1. Para ello, se construye la función *scaler_function*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scaler_function(X1, X2, X3, scale=True):\n",
    "    scaler = StandardScaler(with_std=scale).fit(Xtr)\n",
    "    Xtr_scaled = scaler.transform(X1)\n",
    "    Xts_scaled = scaler.transform(X2)\n",
    "    Xv_scaled = scaler.transform(X3)\n",
    "    return Xtr_scaled, Xts_scaled, Xv_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, bajo esta estrategia, se escalan las tres matrices originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Seba/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/Seba/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/Seba/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/Seba/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtr_scaled, Xts_scaled, Xv_scaled = scaler_function(Xtr, Xts, Xv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sin embargo, es necesario precisar que la media de las matrices son muy cercanas a 0, pero no completamente 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.10516057e-16,  -5.55111512e-19,  -1.22137855e-16, ...,\n",
       "         1.36955558e-15,  -1.32736044e-16,   1.22275523e-16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Por otro lado, las varianzas son exactamente 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4 Construcción de redes neuronales para problema de reconocimiento de imágenes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se transforman los vectores Ytr, Yts e Yv a matrices categóricas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ytr = to_categorical(Ytr)\n",
    "Yts = to_categorical(Yts)\n",
    "Yv = to_categorical(Yv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera arquitectura de red neuronal con que se trabaja es una DNN (*Deep Sequential Neural Network*), que corresponde a una clase de red totalmente conectada que procesa datos de forma secuencial a través de sus capas. En este caso, se crea una red con 100 capas ocultas y se ocupa la función de activación de capas *relu*. Posterior a ello, se elimina aleatoriamente el 10% de las capas y se agregan 10 nuevas, pero considerando la función de activación *softmax* para estas últimas. Después de aplicar tales ajuste, se compila el modelo. Una vez compilado, se procede a optimizar el modelo obtenido, es decir, en base a los valores que se obtienen para la función de perdida y para la precisión del modelo aplicado sobre el conjunto de validación, se realizan ajustes en dicho modelo, re-calculando, por ejemplo, los hiper parámetros. Se realizan, en total, 50 iteraciones de optimización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 12s - loss: 0.2695 - acc: 0.9032 - val_loss: 0.2456 - val_acc: 0.9084\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2452 - acc: 0.9082 - val_loss: 0.2307 - val_acc: 0.9112\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2357 - acc: 0.9109 - val_loss: 0.2195 - val_acc: 0.9155\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2291 - acc: 0.9133 - val_loss: 0.2134 - val_acc: 0.9181\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2236 - acc: 0.9153 - val_loss: 0.2094 - val_acc: 0.9189\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2197 - acc: 0.9164 - val_loss: 0.2046 - val_acc: 0.9210\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2155 - acc: 0.9177 - val_loss: 0.2024 - val_acc: 0.9206\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2122 - acc: 0.9186 - val_loss: 0.1990 - val_acc: 0.9232\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2093 - acc: 0.9200 - val_loss: 0.1953 - val_acc: 0.9256\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2063 - acc: 0.9208 - val_loss: 0.1935 - val_acc: 0.9260\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2040 - acc: 0.9214 - val_loss: 0.1899 - val_acc: 0.9270\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2012 - acc: 0.9226 - val_loss: 0.1838 - val_acc: 0.9306\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1995 - acc: 0.9232 - val_loss: 0.1828 - val_acc: 0.9304\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1977 - acc: 0.9240 - val_loss: 0.1839 - val_acc: 0.9298\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1953 - acc: 0.9247 - val_loss: 0.1790 - val_acc: 0.9328\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1935 - acc: 0.9254 - val_loss: 0.1764 - val_acc: 0.9318\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1916 - acc: 0.9260 - val_loss: 0.1769 - val_acc: 0.9340\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1903 - acc: 0.9269 - val_loss: 0.1737 - val_acc: 0.9346\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1886 - acc: 0.9271 - val_loss: 0.1704 - val_acc: 0.9359\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1871 - acc: 0.9279 - val_loss: 0.1703 - val_acc: 0.9359\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 12s - loss: 0.1852 - acc: 0.9286 - val_loss: 0.1671 - val_acc: 0.9361\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1838 - acc: 0.9291 - val_loss: 0.1677 - val_acc: 0.9358\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1826 - acc: 0.9296 - val_loss: 0.1645 - val_acc: 0.9369\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1810 - acc: 0.9300 - val_loss: 0.1635 - val_acc: 0.9382\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1798 - acc: 0.9306 - val_loss: 0.1602 - val_acc: 0.9403\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1783 - acc: 0.9311 - val_loss: 0.1619 - val_acc: 0.9388\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1777 - acc: 0.9314 - val_loss: 0.1556 - val_acc: 0.9412\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1761 - acc: 0.9322 - val_loss: 0.1574 - val_acc: 0.9413\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1753 - acc: 0.9326 - val_loss: 0.1552 - val_acc: 0.9424\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1745 - acc: 0.9327 - val_loss: 0.1535 - val_acc: 0.9430\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1729 - acc: 0.9336 - val_loss: 0.1520 - val_acc: 0.9442\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1717 - acc: 0.9341 - val_loss: 0.1500 - val_acc: 0.9453\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1699 - acc: 0.9345 - val_loss: 0.1499 - val_acc: 0.9435\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1699 - acc: 0.9345 - val_loss: 0.1497 - val_acc: 0.9421\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1681 - acc: 0.9352 - val_loss: 0.1501 - val_acc: 0.9436\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1673 - acc: 0.9355 - val_loss: 0.1429 - val_acc: 0.9475\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1659 - acc: 0.9360 - val_loss: 0.1454 - val_acc: 0.9451\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1657 - acc: 0.9361 - val_loss: 0.1418 - val_acc: 0.9466\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1643 - acc: 0.9365 - val_loss: 0.1434 - val_acc: 0.9463\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1634 - acc: 0.9371 - val_loss: 0.1402 - val_acc: 0.9507\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1624 - acc: 0.9372 - val_loss: 0.1408 - val_acc: 0.9480\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1610 - acc: 0.9382 - val_loss: 0.1365 - val_acc: 0.9500\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1608 - acc: 0.9377 - val_loss: 0.1382 - val_acc: 0.9477\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1608 - acc: 0.9380 - val_loss: 0.1391 - val_acc: 0.9488\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1591 - acc: 0.9388 - val_loss: 0.1347 - val_acc: 0.9515\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1583 - acc: 0.9386 - val_loss: 0.1352 - val_acc: 0.9509\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1580 - acc: 0.9394 - val_loss: 0.1335 - val_acc: 0.9524\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1564 - acc: 0.9400 - val_loss: 0.1374 - val_acc: 0.9496\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1556 - acc: 0.9401 - val_loss: 0.1379 - val_acc: 0.9479\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.1557 - acc: 0.9400 - val_loss: 0.1303 - val_acc: 0.9552\n",
      " 992/1000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=Xtr_scaled.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(Xtr_scaled, Ytr, nb_epoch=50, batch_size=32, verbose=1, validation_data=(Xv_scaled,Yv))\n",
    "scores = model.evaluate(Xv_scaled, Yv)\n",
    "test_acc = scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados del código anterior muestran que en, en promedio, cada iteración de optimización demora 10.64 [s], sumando un tiempo de 532 [s] para el total de iteraciones. Se puede ver como, tanto para el conjunto de entrenamiento como el validación, la función de pérdida experimenta una reducción considerable y a su vez, la precisión aumenta en una proporción no menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa una nueva red, pero se cambia la función de activación de neuronas: Ahora se utiliza *sigmoid*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.3004 - acc: 0.9000 - val_loss: 0.2820 - val_acc: 0.9000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2780 - acc: 0.9010 - val_loss: 0.2697 - val_acc: 0.9017\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2701 - acc: 0.9025 - val_loss: 0.2635 - val_acc: 0.9038\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2648 - acc: 0.9039 - val_loss: 0.2583 - val_acc: 0.9057\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2611 - acc: 0.9051 - val_loss: 0.2549 - val_acc: 0.9065\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2579 - acc: 0.9061 - val_loss: 0.2514 - val_acc: 0.9077\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2552 - acc: 0.9067 - val_loss: 0.2490 - val_acc: 0.9087\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2532 - acc: 0.9076 - val_loss: 0.2467 - val_acc: 0.9098\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2514 - acc: 0.9083 - val_loss: 0.2442 - val_acc: 0.9116\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2497 - acc: 0.9087 - val_loss: 0.2430 - val_acc: 0.9103\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2482 - acc: 0.9095 - val_loss: 0.2414 - val_acc: 0.9118\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2468 - acc: 0.9099 - val_loss: 0.2389 - val_acc: 0.9124\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2457 - acc: 0.9104 - val_loss: 0.2380 - val_acc: 0.9132\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2444 - acc: 0.9108 - val_loss: 0.2365 - val_acc: 0.9124\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 12s - loss: 0.2433 - acc: 0.9111 - val_loss: 0.2352 - val_acc: 0.9126\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 12s - loss: 0.2425 - acc: 0.9114 - val_loss: 0.2340 - val_acc: 0.9134\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2415 - acc: 0.9119 - val_loss: 0.2332 - val_acc: 0.9132\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2405 - acc: 0.9120 - val_loss: 0.2315 - val_acc: 0.9147\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2397 - acc: 0.9125 - val_loss: 0.2310 - val_acc: 0.9153\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2389 - acc: 0.9128 - val_loss: 0.2303 - val_acc: 0.9150\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2380 - acc: 0.9130 - val_loss: 0.2288 - val_acc: 0.9162\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2370 - acc: 0.9134 - val_loss: 0.2280 - val_acc: 0.9156\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2362 - acc: 0.9137 - val_loss: 0.2266 - val_acc: 0.9164\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2356 - acc: 0.9140 - val_loss: 0.2260 - val_acc: 0.9163\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2347 - acc: 0.9140 - val_loss: 0.2249 - val_acc: 0.9174\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2340 - acc: 0.9144 - val_loss: 0.2237 - val_acc: 0.9182\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2334 - acc: 0.9146 - val_loss: 0.2233 - val_acc: 0.9180\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2327 - acc: 0.9148 - val_loss: 0.2224 - val_acc: 0.9185\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2320 - acc: 0.9151 - val_loss: 0.2210 - val_acc: 0.9187\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2312 - acc: 0.9152 - val_loss: 0.2203 - val_acc: 0.9199\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 12s - loss: 0.2306 - acc: 0.9158 - val_loss: 0.2207 - val_acc: 0.9179\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 12s - loss: 0.2302 - acc: 0.9157 - val_loss: 0.2200 - val_acc: 0.9194\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2295 - acc: 0.9159 - val_loss: 0.2181 - val_acc: 0.9199\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 11s - loss: 0.2290 - acc: 0.9161 - val_loss: 0.2174 - val_acc: 0.9215\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2283 - acc: 0.9165 - val_loss: 0.2169 - val_acc: 0.9205\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2281 - acc: 0.9164 - val_loss: 0.2163 - val_acc: 0.9213\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2278 - acc: 0.9166 - val_loss: 0.2155 - val_acc: 0.9217\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2265 - acc: 0.9169 - val_loss: 0.2149 - val_acc: 0.9220\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2260 - acc: 0.9171 - val_loss: 0.2135 - val_acc: 0.9228\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2255 - acc: 0.9176 - val_loss: 0.2128 - val_acc: 0.9226\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2251 - acc: 0.9174 - val_loss: 0.2127 - val_acc: 0.9229\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2247 - acc: 0.9177 - val_loss: 0.2119 - val_acc: 0.9229\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2240 - acc: 0.9177 - val_loss: 0.2109 - val_acc: 0.9238\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2237 - acc: 0.9178 - val_loss: 0.2104 - val_acc: 0.9223\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2229 - acc: 0.9183 - val_loss: 0.2094 - val_acc: 0.9235\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2224 - acc: 0.9184 - val_loss: 0.2097 - val_acc: 0.9244\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2216 - acc: 0.9185 - val_loss: 0.2084 - val_acc: 0.9248\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2216 - acc: 0.9187 - val_loss: 0.2085 - val_acc: 0.9243\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2210 - acc: 0.9187 - val_loss: 0.2078 - val_acc: 0.9243\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 10s - loss: 0.2204 - acc: 0.9190 - val_loss: 0.2066 - val_acc: 0.9251\n",
      " 960/1000 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=Xtr_scaled.shape[1], init='uniform', activation='sigmoid'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(Xtr_scaled, Ytr, nb_epoch=50, batch_size=32, verbose=1, validation_data=(Xv_scaled,Yv))\n",
    "scores = model.evaluate(Xv_scaled, Yv)\n",
    "test_acc = scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al usar la función de activación *sigmoid*, se obtiene una tiempo promedio de 10.98 [s] por iteración en el proceso de optimización del modelo, siendo el total de 549 [s], por lo que requiere de un tiempo mayor respecto al modelo que usó la función de activación *relu*. Además, si bien la función de perdida se reduce y la precisión aumenta al culminar este proceso, no mejora los valores obtenidos por el modelo anterior, como por ejemplo, la precisión sobre el conjunto de validación, que para el caso anterior alcanzó su valor óptimo en 0.9526, mientras que en este caso el óptimo fue 0.9219.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se estudia el resultado de reducir la cantidad de capas presentes en la red a casi la mitad, esto es, 55 capas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2765 - acc: 0.9024 - val_loss: 0.2493 - val_acc: 0.9071\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2523 - acc: 0.9060 - val_loss: 0.2362 - val_acc: 0.9089\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2435 - acc: 0.9089 - val_loss: 0.2279 - val_acc: 0.9124\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2374 - acc: 0.9104 - val_loss: 0.2240 - val_acc: 0.9122\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2332 - acc: 0.9120 - val_loss: 0.2196 - val_acc: 0.9147\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2296 - acc: 0.9130 - val_loss: 0.2136 - val_acc: 0.9168\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2264 - acc: 0.9140 - val_loss: 0.2125 - val_acc: 0.9176\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2237 - acc: 0.9149 - val_loss: 0.2105 - val_acc: 0.9196\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2210 - acc: 0.9157 - val_loss: 0.2048 - val_acc: 0.9205\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2191 - acc: 0.9163 - val_loss: 0.2029 - val_acc: 0.9218\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2170 - acc: 0.9171 - val_loss: 0.2033 - val_acc: 0.9208\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2159 - acc: 0.9175 - val_loss: 0.1983 - val_acc: 0.9247\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2142 - acc: 0.9181 - val_loss: 0.1985 - val_acc: 0.9238\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2121 - acc: 0.9187 - val_loss: 0.1959 - val_acc: 0.9247\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2108 - acc: 0.9192 - val_loss: 0.1937 - val_acc: 0.9256\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2098 - acc: 0.9195 - val_loss: 0.1943 - val_acc: 0.9252\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2083 - acc: 0.9200 - val_loss: 0.1919 - val_acc: 0.9247\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2067 - acc: 0.9205 - val_loss: 0.1884 - val_acc: 0.9286\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2058 - acc: 0.9208 - val_loss: 0.1882 - val_acc: 0.9290\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2045 - acc: 0.9214 - val_loss: 0.1868 - val_acc: 0.9287\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2031 - acc: 0.9218 - val_loss: 0.1879 - val_acc: 0.9283\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2025 - acc: 0.9219 - val_loss: 0.1851 - val_acc: 0.9301\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2018 - acc: 0.9221 - val_loss: 0.1852 - val_acc: 0.9297\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.2010 - acc: 0.9224 - val_loss: 0.1805 - val_acc: 0.9311\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.1995 - acc: 0.9230 - val_loss: 0.1828 - val_acc: 0.9303\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.1987 - acc: 0.9235 - val_loss: 0.1805 - val_acc: 0.9304\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.1979 - acc: 0.9235 - val_loss: 0.1796 - val_acc: 0.9303\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.1968 - acc: 0.9238 - val_loss: 0.1794 - val_acc: 0.9303\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.1965 - acc: 0.9241 - val_loss: 0.1772 - val_acc: 0.9325\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.1957 - acc: 0.9244 - val_loss: 0.1782 - val_acc: 0.9308\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1948 - acc: 0.9245 - val_loss: 0.1746 - val_acc: 0.9340\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1940 - acc: 0.9252 - val_loss: 0.1748 - val_acc: 0.9320\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1936 - acc: 0.9251 - val_loss: 0.1722 - val_acc: 0.9341\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1922 - acc: 0.9259 - val_loss: 0.1754 - val_acc: 0.9320\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1919 - acc: 0.9260 - val_loss: 0.1726 - val_acc: 0.9339\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1912 - acc: 0.9261 - val_loss: 0.1735 - val_acc: 0.9329\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1903 - acc: 0.9266 - val_loss: 0.1731 - val_acc: 0.9338\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1902 - acc: 0.9264 - val_loss: 0.1723 - val_acc: 0.9339\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1895 - acc: 0.9264 - val_loss: 0.1707 - val_acc: 0.9359\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1890 - acc: 0.9267 - val_loss: 0.1674 - val_acc: 0.9371\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1887 - acc: 0.9271 - val_loss: 0.1694 - val_acc: 0.9341\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1876 - acc: 0.9273 - val_loss: 0.1661 - val_acc: 0.9363\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1866 - acc: 0.9280 - val_loss: 0.1666 - val_acc: 0.9364\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1866 - acc: 0.9278 - val_loss: 0.1681 - val_acc: 0.9344\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1858 - acc: 0.9280 - val_loss: 0.1649 - val_acc: 0.9354\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1855 - acc: 0.9282 - val_loss: 0.1636 - val_acc: 0.9373\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1843 - acc: 0.9286 - val_loss: 0.1654 - val_acc: 0.9341\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1844 - acc: 0.9285 - val_loss: 0.1636 - val_acc: 0.9368\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1838 - acc: 0.9290 - val_loss: 0.1619 - val_acc: 0.9364\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1827 - acc: 0.9295 - val_loss: 0.1627 - val_acc: 0.9383\n",
      " 928/1000 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=Xtr_scaled.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(Xtr_scaled, Ytr, nb_epoch=50, batch_size=32, verbose=1, validation_data=(Xv_scaled,Yv))\n",
    "scores = model.evaluate(Xv_scaled, Yv)\n",
    "test_acc = scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados muestran que al utilizar la misma función de activación que en el primer modelo, pero reduciendo la cantidad de capas a 50 disminuye el tiempo de optimización a 8.2 [s] en promedio por iteración. Sin embargo, la precisión sobre el conjunto de validación es de 0.9373, inferior al valor 0.9526 del primer modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**3.5 Cambio en el formato de representación de imágenes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se estudian dos nuevos formatos de representación de los datos: El primero, corresponde a un histograma de tonos. El segundo, a descriptores HOG. En el siguiente código, se crean estas dos representaciones, junto con una tercera representación que combina los atributos de las anteriores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 32, 32, 3)\n",
      "(1000, 32, 32, 3)\n",
      "(1000, 32, 32, 3)\n",
      "(1000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "features1_tr = extract_features(Xtr_scaled,[hog_features]) #extrae hog features\n",
    "features2_tr = extract_features(Xtr_scaled,[color_histogram_hsv]) #extrae histogramas de color\n",
    "features3_tr = extract_features(Xtr_scaled,[hog_features, color_histogram_hsv]) #extrae todo\n",
    "\n",
    "features1_v = extract_features(Xv_scaled,[hog_features]) #extrae hog features\n",
    "features2_v = extract_features(Xv_scaled,[color_histogram_hsv]) #extrae histogramas de color\n",
    "features3_v = extract_features(Xv_scaled,[hog_features, color_histogram_hsv]) #extrae todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la representación mediante descripores HOG, se entrena red neuronal de 50 capas y función de activación *relu* (se han considerado los resultados de la sección anterior). Se ha reducido la cantidad de capas, dado a que inicialmente se intentó utilizar 100 de ellas, pero el costo en términos de tiempo resultó ser muy alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3251 - acc: 0.9000 - val_loss: 0.3250 - val_acc: 0.9000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3250 - acc: 0.9000 - val_loss: 0.3250 - val_acc: 0.9000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3250 - acc: 0.9000 - val_loss: 0.3250 - val_acc: 0.9000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3250 - acc: 0.9000 - val_loss: 0.3249 - val_acc: 0.9000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3249 - acc: 0.9000 - val_loss: 0.3249 - val_acc: 0.9000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3248 - acc: 0.9000 - val_loss: 0.3248 - val_acc: 0.9000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3247 - acc: 0.9000 - val_loss: 0.3247 - val_acc: 0.9000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3246 - acc: 0.9000 - val_loss: 0.3246 - val_acc: 0.9000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3245 - acc: 0.9000 - val_loss: 0.3245 - val_acc: 0.9000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3243 - acc: 0.9000 - val_loss: 0.3243 - val_acc: 0.9000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3241 - acc: 0.9000 - val_loss: 0.3240 - val_acc: 0.9000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3237 - acc: 0.9000 - val_loss: 0.3237 - val_acc: 0.9000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3233 - acc: 0.9000 - val_loss: 0.3232 - val_acc: 0.9000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3228 - acc: 0.9000 - val_loss: 0.3226 - val_acc: 0.9000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3221 - acc: 0.9000 - val_loss: 0.3219 - val_acc: 0.9000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3212 - acc: 0.9000 - val_loss: 0.3210 - val_acc: 0.9000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3200 - acc: 0.9000 - val_loss: 0.3198 - val_acc: 0.9000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3186 - acc: 0.9000 - val_loss: 0.3183 - val_acc: 0.9000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3168 - acc: 0.9000 - val_loss: 0.3165 - val_acc: 0.9000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3147 - acc: 0.9000 - val_loss: 0.3144 - val_acc: 0.9000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3124 - acc: 0.9000 - val_loss: 0.3120 - val_acc: 0.9000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3097 - acc: 0.9000 - val_loss: 0.3094 - val_acc: 0.9000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3070 - acc: 0.9000 - val_loss: 0.3068 - val_acc: 0.9000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3042 - acc: 0.9000 - val_loss: 0.3041 - val_acc: 0.9000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3014 - acc: 0.9000 - val_loss: 0.3014 - val_acc: 0.9000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2987 - acc: 0.9000 - val_loss: 0.2989 - val_acc: 0.9000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2960 - acc: 0.9000 - val_loss: 0.2964 - val_acc: 0.9002\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2936 - acc: 0.9001 - val_loss: 0.2941 - val_acc: 0.9002\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2911 - acc: 0.9002 - val_loss: 0.2919 - val_acc: 0.9002\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2889 - acc: 0.9002 - val_loss: 0.2900 - val_acc: 0.9002\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2869 - acc: 0.9002 - val_loss: 0.2882 - val_acc: 0.9001\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2852 - acc: 0.9003 - val_loss: 0.2865 - val_acc: 0.9001\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2836 - acc: 0.9003 - val_loss: 0.2851 - val_acc: 0.9003\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2820 - acc: 0.9003 - val_loss: 0.2838 - val_acc: 0.9002\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2806 - acc: 0.9004 - val_loss: 0.2828 - val_acc: 0.9005\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2794 - acc: 0.9005 - val_loss: 0.2817 - val_acc: 0.9004\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2785 - acc: 0.9005 - val_loss: 0.2807 - val_acc: 0.9005\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2775 - acc: 0.9005 - val_loss: 0.2799 - val_acc: 0.9007\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2765 - acc: 0.9006 - val_loss: 0.2791 - val_acc: 0.9008\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2757 - acc: 0.9007 - val_loss: 0.2783 - val_acc: 0.9008\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2749 - acc: 0.9007 - val_loss: 0.2776 - val_acc: 0.9010\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2740 - acc: 0.9008 - val_loss: 0.2769 - val_acc: 0.9010\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2733 - acc: 0.9009 - val_loss: 0.2762 - val_acc: 0.9010\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2725 - acc: 0.9010 - val_loss: 0.2756 - val_acc: 0.9010\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2718 - acc: 0.9011 - val_loss: 0.2750 - val_acc: 0.9012\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2712 - acc: 0.9012 - val_loss: 0.2743 - val_acc: 0.9012\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2705 - acc: 0.9013 - val_loss: 0.2739 - val_acc: 0.9011\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2699 - acc: 0.9014 - val_loss: 0.2732 - val_acc: 0.9012\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2693 - acc: 0.9015 - val_loss: 0.2726 - val_acc: 0.9014\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2687 - acc: 0.9016 - val_loss: 0.2720 - val_acc: 0.9015\n",
      " 800/1000 [=======================>......] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=features1_tr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features1_tr, Ytr, nb_epoch=50, batch_size=32, verbose=1, validation_data=(features1_v,Yv))\n",
    "scores = model.evaluate(features1_v, Yv)\n",
    "test_acc = scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los resultados, se puede ver como la precisión sobre el conjunto de validación aumenta muy poco a lo largo del proceso de optimización (De hecho, sólo empieza a mejorar a partir de la iteración 27). Por otro lado, el tiempo de cómputo se reduce en una cantidad no menor, siendo de aproximadamente 2.74 [s] en promedio por iteración, con un tiempo total de 137 [s]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la representación mediante histogramas de tonos, se entrena red neuronal de 50 capas y función de activación *relu*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3250 - acc: 0.9000 - val_loss: 0.3249 - val_acc: 0.9000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3249 - acc: 0.9000 - val_loss: 0.3247 - val_acc: 0.9000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3245 - acc: 0.9000 - val_loss: 0.3242 - val_acc: 0.9000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3239 - acc: 0.9000 - val_loss: 0.3233 - val_acc: 0.9000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3226 - acc: 0.9000 - val_loss: 0.3214 - val_acc: 0.9000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3203 - acc: 0.9000 - val_loss: 0.3183 - val_acc: 0.9000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3167 - acc: 0.9000 - val_loss: 0.3140 - val_acc: 0.9000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3126 - acc: 0.9000 - val_loss: 0.3095 - val_acc: 0.9000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3088 - acc: 0.9000 - val_loss: 0.3060 - val_acc: 0.9000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3062 - acc: 0.9000 - val_loss: 0.3036 - val_acc: 0.9000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3047 - acc: 0.9000 - val_loss: 0.3022 - val_acc: 0.9000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3039 - acc: 0.9000 - val_loss: 0.3013 - val_acc: 0.9000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3032 - acc: 0.9000 - val_loss: 0.3008 - val_acc: 0.9000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3028 - acc: 0.9000 - val_loss: 0.3003 - val_acc: 0.9000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3023 - acc: 0.9000 - val_loss: 0.3000 - val_acc: 0.9000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3020 - acc: 0.9000 - val_loss: 0.2995 - val_acc: 0.9000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3018 - acc: 0.9000 - val_loss: 0.2992 - val_acc: 0.9000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3014 - acc: 0.9000 - val_loss: 0.2989 - val_acc: 0.9000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3011 - acc: 0.9000 - val_loss: 0.2986 - val_acc: 0.9000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3007 - acc: 0.9000 - val_loss: 0.2983 - val_acc: 0.9000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3003 - acc: 0.9000 - val_loss: 0.2980 - val_acc: 0.9000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3000 - acc: 0.9000 - val_loss: 0.2977 - val_acc: 0.9000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2997 - acc: 0.9000 - val_loss: 0.2975 - val_acc: 0.9000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2993 - acc: 0.9000 - val_loss: 0.2973 - val_acc: 0.9000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2991 - acc: 0.9000 - val_loss: 0.2970 - val_acc: 0.9000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2989 - acc: 0.9000 - val_loss: 0.2969 - val_acc: 0.9000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2987 - acc: 0.9000 - val_loss: 0.2968 - val_acc: 0.9000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2985 - acc: 0.9000 - val_loss: 0.2966 - val_acc: 0.9000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2984 - acc: 0.9000 - val_loss: 0.2966 - val_acc: 0.9000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2983 - acc: 0.9000 - val_loss: 0.2964 - val_acc: 0.9000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2981 - acc: 0.9000 - val_loss: 0.2963 - val_acc: 0.9000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2980 - acc: 0.9000 - val_loss: 0.2961 - val_acc: 0.9000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2979 - acc: 0.9000 - val_loss: 0.2961 - val_acc: 0.9000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2978 - acc: 0.9000 - val_loss: 0.2960 - val_acc: 0.9000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2977 - acc: 0.9000 - val_loss: 0.2959 - val_acc: 0.9000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2977 - acc: 0.9000 - val_loss: 0.2957 - val_acc: 0.9000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2975 - acc: 0.9000 - val_loss: 0.2957 - val_acc: 0.9000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2975 - acc: 0.9000 - val_loss: 0.2956 - val_acc: 0.9000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2972 - acc: 0.9000 - val_loss: 0.2954 - val_acc: 0.9000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2972 - acc: 0.9000 - val_loss: 0.2954 - val_acc: 0.9000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2972 - acc: 0.9000 - val_loss: 0.2953 - val_acc: 0.9000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2970 - acc: 0.9000 - val_loss: 0.2951 - val_acc: 0.9000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2970 - acc: 0.9000 - val_loss: 0.2950 - val_acc: 0.9000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2969 - acc: 0.9000 - val_loss: 0.2948 - val_acc: 0.9000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2968 - acc: 0.9000 - val_loss: 0.2948 - val_acc: 0.9000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2968 - acc: 0.9000 - val_loss: 0.2947 - val_acc: 0.9000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2966 - acc: 0.9000 - val_loss: 0.2945 - val_acc: 0.9000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2965 - acc: 0.9000 - val_loss: 0.2945 - val_acc: 0.9000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2964 - acc: 0.9000 - val_loss: 0.2944 - val_acc: 0.9000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2964 - acc: 0.9000 - val_loss: 0.2943 - val_acc: 0.9000\n",
      " 992/1000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=features2_tr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features2_tr, Ytr, nb_epoch=50, batch_size=32, verbose=1, validation_data=(features2_v,Yv))\n",
    "scores = model.evaluate(features2_v, Yv)\n",
    "test_acc = scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando los resultados, se puede ver como la precisión sobre el conjunto de validación aumenta muy poco a lo largo del proceso de optimización, siendo obteniendose valores para la función de perdida y precisión inferiores a los conseguidos con la representación mediante descriptores HOG. Por otro lado, el tiempo de cómputo se reduce  a  2[s] en promedio por iteración, con un tiempo total de 100 [s]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la representación combinada de descripores HOG e histogramas de color, se entrena red neuronal de 50 capas y función de activación *relu*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.3250 - acc: 0.9000 - val_loss: 0.3248 - val_acc: 0.9000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3247 - acc: 0.9000 - val_loss: 0.3245 - val_acc: 0.9000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3241 - acc: 0.9000 - val_loss: 0.3237 - val_acc: 0.9000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3230 - acc: 0.9000 - val_loss: 0.3220 - val_acc: 0.9000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3208 - acc: 0.9000 - val_loss: 0.3191 - val_acc: 0.9000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3172 - acc: 0.9000 - val_loss: 0.3145 - val_acc: 0.9000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3123 - acc: 0.9000 - val_loss: 0.3091 - val_acc: 0.9000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3074 - acc: 0.9000 - val_loss: 0.3042 - val_acc: 0.9000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3034 - acc: 0.9000 - val_loss: 0.3005 - val_acc: 0.9000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.3004 - acc: 0.9000 - val_loss: 0.2977 - val_acc: 0.9000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2982 - acc: 0.9000 - val_loss: 0.2957 - val_acc: 0.9000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2965 - acc: 0.9000 - val_loss: 0.2939 - val_acc: 0.9000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2947 - acc: 0.9000 - val_loss: 0.2923 - val_acc: 0.9000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2932 - acc: 0.9000 - val_loss: 0.2907 - val_acc: 0.9000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2916 - acc: 0.9000 - val_loss: 0.2890 - val_acc: 0.9000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2897 - acc: 0.9000 - val_loss: 0.2873 - val_acc: 0.9000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2880 - acc: 0.9001 - val_loss: 0.2855 - val_acc: 0.9000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2862 - acc: 0.9001 - val_loss: 0.2837 - val_acc: 0.9000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2841 - acc: 0.9001 - val_loss: 0.2818 - val_acc: 0.9001\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2822 - acc: 0.9001 - val_loss: 0.2800 - val_acc: 0.9001\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2800 - acc: 0.9001 - val_loss: 0.2781 - val_acc: 0.9001\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2783 - acc: 0.9001 - val_loss: 0.2764 - val_acc: 0.9001\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2765 - acc: 0.9001 - val_loss: 0.2746 - val_acc: 0.9001\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2746 - acc: 0.9002 - val_loss: 0.2730 - val_acc: 0.8999\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2729 - acc: 0.9003 - val_loss: 0.2714 - val_acc: 0.8999\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2713 - acc: 0.9003 - val_loss: 0.2701 - val_acc: 0.8997\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2699 - acc: 0.9003 - val_loss: 0.2690 - val_acc: 0.9001\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2684 - acc: 0.9005 - val_loss: 0.2676 - val_acc: 0.9001\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2672 - acc: 0.9005 - val_loss: 0.2665 - val_acc: 0.8997\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2660 - acc: 0.9007 - val_loss: 0.2655 - val_acc: 0.9001\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2651 - acc: 0.9006 - val_loss: 0.2647 - val_acc: 0.9000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2640 - acc: 0.9008 - val_loss: 0.2637 - val_acc: 0.9002\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2630 - acc: 0.9009 - val_loss: 0.2629 - val_acc: 0.9000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2620 - acc: 0.9009 - val_loss: 0.2621 - val_acc: 0.9005\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2612 - acc: 0.9011 - val_loss: 0.2614 - val_acc: 0.9003\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2604 - acc: 0.9012 - val_loss: 0.2607 - val_acc: 0.9005\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2596 - acc: 0.9013 - val_loss: 0.2599 - val_acc: 0.9009\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2590 - acc: 0.9014 - val_loss: 0.2593 - val_acc: 0.9006\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2582 - acc: 0.9016 - val_loss: 0.2587 - val_acc: 0.9011\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2573 - acc: 0.9018 - val_loss: 0.2580 - val_acc: 0.9013\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2566 - acc: 0.9019 - val_loss: 0.2574 - val_acc: 0.9018\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2558 - acc: 0.9021 - val_loss: 0.2568 - val_acc: 0.9020\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2551 - acc: 0.9022 - val_loss: 0.2561 - val_acc: 0.9019\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2545 - acc: 0.9025 - val_loss: 0.2555 - val_acc: 0.9018\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2537 - acc: 0.9027 - val_loss: 0.2549 - val_acc: 0.9020\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s - loss: 0.2533 - acc: 0.9028 - val_loss: 0.2542 - val_acc: 0.9019\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2522 - acc: 0.9029 - val_loss: 0.2535 - val_acc: 0.9020\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2519 - acc: 0.9031 - val_loss: 0.2530 - val_acc: 0.9024\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2511 - acc: 0.9035 - val_loss: 0.2522 - val_acc: 0.9021\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s - loss: 0.2502 - acc: 0.9036 - val_loss: 0.2516 - val_acc: 0.9022\n",
      " 992/1000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=features3_tr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features3_tr, Ytr, nb_epoch=50, batch_size=32, verbose=1, validation_data=(features3_v,Yv))\n",
    "scores = model.evaluate(features3_v, Yv)\n",
    "test_acc = scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar los resultados anteriores, se observa como, al finalizar el proceso de optimización, la precisión sobre el conjunto de validación resulta ser superior con respecto a cada una de las dos representación anteriores. Además, El tiempo total de cómputo es 116 [s], es decir, 2.32 [s] en promedio por iteración, tiempo que, si bien es superior al alcanzando usando sólo descriptores HOG, es a su vez inferior al alcanzando con histogramas de tonos. Luego, se considera como la mejor opción de las tres estudiadas para construir el modelo y se utilizará en las secciones siguientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**3.6 Resolución del problema por medio de una SVR no lineal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, se entrena SVR sobre representación original de imágenes, con parámetro de regularización C = 1, dados los buenos resultados obtenidos al usar este valor. Tomar en cuenta que el entrenamiento de la SVR puede tomar varias horas de ejecución, lo que muestra que no es el método más indicado para abarcar este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Seba/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/Seba/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/Seba/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/Seba/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtr, Ytr, Xts, Yts, Xv, Yv = load_CIFAR10('.')\n",
    "Xtr_scaled, Xts_scaled, Xv_scaled = scaler_function(Xtr, Xts, Xv)\n",
    "\n",
    "model = SVR(C=1,epsilon=0.01)\n",
    "model.fit(Xtr_scaled,Ytr)\n",
    "score_tr = model.score(Xtr_scaled, Ytr)\n",
    "score_v = model.predict(Xv_scaled, Yv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los scores obtenidos son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Precisión sobre conjunto de entrenamiento:\", score_tr\n",
    "print \"Precisión sobre conjunto de validación:\", score_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se entrena una SVR con los mismos parámetros del caso anterior, pero ahora sobre la representación combinada de descriptores HOG e histogramas de tonos, pues es la que consiguió los mejores resultados en la sección anterior. El tiempo de entrenamiento de este modelo también puede requerir de varias horas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features3_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-92cc1cdd4cd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures3_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscore_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures3_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscore_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures3_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features3_tr' is not defined"
     ]
    }
   ],
   "source": [
    "model = SVR(C=1,epsilon=0.01)\n",
    "model.fit(features3_tr,Ytr)\n",
    "score_tr = model.score(features3_tr, Ytr)\n",
    "score_v = model.score(features3_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los scores obtenidos son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Precisión sobre conjunto de entrenamiento:\", score_tr\n",
    "print \"Precisión sobre conjunto de validación:\", score_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.7 Resolución del problema por medio de un árbol de regresión**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, se entrena árbol de regresión sobre representación original de imágenes, se experimenta con profundidad máxima 10 y 20 (El siguiente código muestra solo para profundidad 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Tree(random_state=0,max_depth=20)\n",
    "model.fit(Xtr_scaled,Ytr)\n",
    "score_tr = model.score(Xtr_scaled, Ytr)\n",
    "score_v = model.score(Xv_scaled, Yv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los scores obtenidos son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión sobre conjunto de entrenamiento: 0.852673959313\n",
      "Precisión sobre conjunto de validación: 0.856074943301\n"
     ]
    }
   ],
   "source": [
    "print \"Precisión sobre conjunto de entrenamiento:\", score_tr\n",
    "print \"Precisión sobre conjunto de validación:\", score_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para profundidad máxima 10, el rendimiento es bastante pobre, siendo la precisión sobre el conjunto de validación apenas del orden de 0.32, pero al aumentar la profundidad a 20, se muestra una gran mejora en el rendimiento sobre el conjunto de validación, siendo del orden de 0.86."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se entrena árbol con los mismos parámetros del caso anterior, pero ahora sobre la representación mediante combinada. La profundidad del árbol nuevamente es 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Tree(random_state=0,max_depth=20)\n",
    "model.fit(features3_tr,Ytr)\n",
    "score_tr = model.score(features3_tr, Ytr)\n",
    "score_v = model.score(features3_v, Yv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los scores obtenidos son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión sobre conjunto de entrenamiento: 0.930198420346\n",
      "Precisión sobre conjunto de validación: 0.921372860818\n"
     ]
    }
   ],
   "source": [
    "print \"Precisión sobre conjunto de entrenamiento:\", score_tr\n",
    "print \"Precisión sobre conjunto de validación:\", score_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados muestran que la precisión sobre el conjunto de validación mejora desde 0.86 a 0.92; aproximadamente, un aumento no menor. Además, se observó que los tiempos de computo fueron menores, por lo que si se quisiera resolver el problema usando un árbol de regresión, conviene utilizar la representación combinada en vez de la representación original."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
